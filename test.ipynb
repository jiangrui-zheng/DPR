{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a765220",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83a6133f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-08T00:46:58.926213714Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/data/jzheng36/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5d8143f71a4ac19fc0a135de05ee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../postprocess/all_examples_0601_hate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m contexts1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(contexts))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Hatemoderate\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../postprocess/all_examples_0601_hate.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m contexts2 \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# hatexplain 4384\u001b[39;00m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/data/installation/anaconda3/envs/negative/lib/python3.8/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../postprocess/all_examples_0601_hate.csv'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# MHS 10354\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "filtered_df = df[df['hate_speech_score'] > 0.5]\n",
    "contexts = filtered_df['text'].tolist()\n",
    "contexts1 = list(set(contexts))\n",
    "\n",
    "# Hatemoderate\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep=\"\\t\")\n",
    "contexts2 = df['sentence'].tolist()\n",
    "\n",
    "# hatexplain 4384\n",
    "dataset = load_dataset(\"hatexplain\")\n",
    "filtered_data = []\n",
    "for entry in dataset[\"train\"]:\n",
    "    labels = entry['annotators']['label']\n",
    "    count_of_0 = labels.count(0)\n",
    "    if count_of_0 >= len(labels) / 2:\n",
    "        filtered_data.append(entry)\n",
    "post_tokens_list = [entry['post_tokens'] for entry in filtered_data]\n",
    "contexts3 = [' '.join(tokens) for tokens in post_tokens_list]\n",
    "\n",
    "# tweets_hate_speech_detection\n",
    "dataset = load_dataset(\"tweets_hate_speech_detection\")\n",
    "contexts5 = [sent for sent, label in zip(dataset['train']['tweet'], dataset['train']['label']) if label == 1]\n",
    "\n",
    "# comments\n",
    "df = pd.read_csv('../raw_datasets/comments.csv', sep = ',' , error_bad_lines=False, header=None, names=['0', '1'])\n",
    "contexts6 = df['1'].tolist()\n",
    "\n",
    "# davidson 4k\n",
    "df = pd.read_csv('../raw_datasets/davidson.csv', sep=\",\", error_bad_lines=False)\n",
    "df = df[df['hate_speech'] != 0]\n",
    "contexts7 = df['tweet'].tolist()\n",
    "\n",
    "# dynahate 22175\n",
    "df = pd.read_csv('../raw_datasets/dynahate.csv', sep=\",\", error_bad_lines=False)\n",
    "df = df[df['label'] == 'hate']\n",
    "contexts8 = df['text'].tolist()\n",
    "len(contexts8)\n",
    "\n",
    "# civil_comments\n",
    "# dataset = load_dataset(\"civil_comments\")\n",
    "# contexts4 = df['sentence'].tolist()\n",
    "\n",
    "combined_contexts = contexts1 + contexts2 + contexts3 + contexts5 + contexts6 + contexts7 + contexts8\n",
    "\n",
    "df_combined = pd.DataFrame({'sentence': combined_contexts})\n",
    "contexts = df_combined['sentence'][:].tolist()\n",
    "contexts = list(set(contexts)) # size 60235"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ceec96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contexts = pd.DataFrame({'contexts': contexts})\n",
    "df_contexts.to_csv('contexts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaf6e9af",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-31T15:31:11.380895354Z"
    },
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/data/jzheng36/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f8e16e6b8e4042813c245b73c36fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 59/59 [01:52<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import os\n",
    "from tqdm import trange, tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep = \"\\t\")\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "\n",
    "#context_model.load_state_dict(torch.load(\"context_model.pth\"))\n",
    "#question_model.load_state_dict(torch.load(\"question_model.pth\"))\n",
    "\n",
    "# contexts = df['sentence'][:].tolist()\n",
    "\n",
    "# dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "# train_data = dataset['train']\n",
    "# df = pd.DataFrame(train_data)\n",
    "# filtered_df = df[df['hate_speech_score'] > 0.5]\n",
    "# contexts = filtered_df['text'].tolist()\n",
    "# contexts = set(contexts)\n",
    "all_context_embeddings = []\n",
    "\n",
    "# Tokenize and compute embeddings in batches\n",
    "batch_size=1024\n",
    "for i in trange(0, len(contexts), batch_size):\n",
    "    batch_contexts = contexts[i: i+batch_size]\n",
    "    context_input_ids = context_tokenizer(batch_contexts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)[\"input_ids\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        context_embeddings = context_model(context_input_ids).pooler_output\n",
    "    all_context_embeddings.append(context_embeddings)\n",
    "\n",
    "all_context_embeddings = torch.cat(all_context_embeddings, dim=0)\n",
    "torch.save(all_context_embeddings, 'all_context_embeddings.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f173ef2",
   "metadata": {},
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aecf278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer\n",
    "import os\n",
    "from tqdm import trange, tqdm\n",
    "from datasets import load_dataset\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "\n",
    "def retrieve_passages(query, all_context_embeddings):\n",
    "    \"\"\"\n",
    "    Retrieve top 5 passages that match the given query using DPR.\n",
    "    :param query: The query string.\n",
    "    :param contexts: List of context passages.\n",
    "    :param batch_size: Size of batches for processing.\n",
    "    :return: Top 5 matching passages.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Tokenize the query and compute its embedding\n",
    "    query_input_ids = question_tokenizer(query, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        query_embeddings = question_model(query_input_ids).pooler_output\n",
    "\n",
    "    # Compute similarity scores\n",
    "    scores = torch.matmul(query_embeddings, all_context_embeddings.T).squeeze()\n",
    "    \n",
    "    print(scores)\n",
    "\n",
    "    # Get the indices of top 5 scores\n",
    "    top_indices = torch.argsort(scores, descending=True)[:10].tolist()\n",
    "\n",
    "    top_scores = scores[top_indices].tolist()\n",
    "\n",
    "    # Get the top 10 contexts based on the indices\n",
    "    top_contexts = [contexts[idx] for idx in top_indices]\n",
    "\n",
    "    return top_contexts, top_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "655090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('contexts.csv')\n",
    "contexts = df['contexts'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7381095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.weight', 'ctx_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "all_context_embeddings = torch.load('all_context_embeddings.pth')\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "\n",
    "# context_model.load_state_dict(torch.load(\"context_model.pth\"))\n",
    "# question_model.load_state_dict(torch.load(\"question_model.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44ceb2",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c6c1fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([51.8427, 54.2000, 53.8861,  ..., 53.1062, 52.7941, 42.4557],\n",
      "       device='cuda:0')\n",
      "women are objects to be used and abused 82.40365600585938\n",
      "Women with masculine spirits are trash. 80.57473754882812\n",
      "Impregnate you violently and then sodomize you 79.72418212890625\n",
      "Women in general are more likely to develop degradation kinks because of societal expectations and stereotypes. it's fucked up but being seen as inferior can cause them to cope by fetishizing it. 79.17147064208984\n",
      "If a man did this to a woman, it would be rape. Hypocrisy, thy name is woman. 78.76933288574219\n",
      "sexism may be harmful to men's mental health...#men  #woman   78.10639953613281\n",
      "women are like beetles; they are gross and disgusting 77.6471939086914\n",
      "Females that are lustful and sexually degenerate are the ugliest of women. 77.6098403930664\n",
      "Women justify a lot of the awful shit they do to men (divorce rape, taking full custody when the man demonstrates he's a good father, false sexual misconduct accusations) by hiding behind the \"patriarchy\". 77.57395935058594\n",
      "Think of women like the cartoon Tasmanian Devil. They are constantly looking for someone or something to ruin and destroy. They pick and insult, question and challenge for no reason other than they have to. They rearrange homes, decorate and then question their choices. They buy new clothes, then question those choices, collect shoes and trinkets because they are overcompensating and then get mad at you because there isn't enough room for all her garbage. Then she turns violent, yelling and screaming, physically attacking because she can't control herself. Her nature is destruction. They are constant chaos because no men and definitely not her father has ever told her to be quiet, sit down and start acting like an adult. 77.4747543334961\n"
     ]
    }
   ],
   "source": [
    "query = \"Dehumanize women as certain objects\"\n",
    "scores, matching_passages = retrieve_passages(query, all_context_embeddings)\n",
    "for passage, score in zip(scores, matching_passages):\n",
    "    print(passage,score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ed836d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48.4239, 55.8075, 56.7317,  ..., 54.8288, 60.5673, 48.6825],\n",
      "       device='cuda:0')\n",
      "muslim ideology is a crippled, low-resolution, cynical look at human nature life and the world we inhabit. 85.03131866455078\n",
      "Islam instructs people to be vicious animals and literally forbids any forms of science and human decency. 84.15936279296875\n",
      "or Muslim men being aggressive & poignantly sneering and rude when others are not looking. 84.15425109863281\n",
      "Caustic, targeted humour is funny - particularly when aimed at politicians or political events. But it has a downside: it tends to defuse outrage at political indecency or dangerous stupidity.  When people should be genuinely offended, and angry enough to object and protest, they often end up snickering at what a comedian said about it. And the humour - the wisecrack reactions to the situation - can become more important than the issue being criticized. 83.82343292236328\n",
      "Offensive cartoons about Mohammed have upset many nations in which Islam is the main religion. How would other countries react if the same type of offensive cartoons had Jesus Christ as the central figure!! I don't think this has gone too far at all. 83.62879943847656\n",
      "\"vandals turned a jewish family's menorah into a swastika\"  #antisemitism  #hate 83.5126724243164\n",
      "Islam treats women like dogs, execute homosexuals and correctly  views liberals as infidels. 82.82620239257812\n",
      "vandals turn a jewish familyâs home menorah into a #swastika |   #bigotry #newswithed  82.77989959716797\n",
      "Islam is a culture of violence 82.74414825439453\n",
      "in america: 'kill obama' and #muslims not welcome here' signs in new mexico draw criticism #islamaphobia  82.39137268066406\n"
     ]
    }
   ],
   "source": [
    "query = \"Mocking or attacking the beliefs of muslims\"\n",
    "scores, matching_passages = retrieve_passages(query, all_context_embeddings)\n",
    "for passage, score in zip(scores, matching_passages):\n",
    "    print(passage,score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49d7fb",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47904ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/data/jzheng36/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fba8de907424d149c722ddbadd4332e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes indeed. She sort of reminds me of the elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The trans women reading this tweet right now i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: These 4 broads who criticize America...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is about time for all illegals to go back t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For starters bend over the one in pink and kic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140202</th>\n",
       "      <td>It is not COVID-19 but #WuhanVirus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140203</th>\n",
       "      <td>@HuXijin_GT Stay hygienic in your eating habit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140204</th>\n",
       "      <td>@Gailyfleur @nytimes Communism created wet mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140205</th>\n",
       "      <td>@CMOMaharashtra Why dont ya say something abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140206</th>\n",
       "      <td>Look at These Chinese Bastards Americaðð...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140207 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text\n",
       "0       Yes indeed. She sort of reminds me of the elde...\n",
       "1       The trans women reading this tweet right now i...\n",
       "2       Question: These 4 broads who criticize America...\n",
       "3       It is about time for all illegals to go back t...\n",
       "4       For starters bend over the one in pink and kic...\n",
       "...                                                   ...\n",
       "140202                 It is not COVID-19 but #WuhanVirus\n",
       "140203  @HuXijin_GT Stay hygienic in your eating habit...\n",
       "140204  @Gailyfleur @nytimes Communism created wet mar...\n",
       "140205  @CMOMaharashtra Why dont ya say something abou...\n",
       "140206  Look at These Chinese Bastards Americaðð...\n",
       "\n",
       "[140207 rows x 1 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first dataset from 'datasets' library\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "contexts1 = dataset[\"train\"][\"text\"]\n",
    "\n",
    "# Load the second dataset from a CSV file using pandas\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep=\"\\t\")\n",
    "contexts2 = df['sentence'].tolist()\n",
    "\n",
    "# Combine the two lists of text\n",
    "combined_contexts = contexts1 + contexts2\n",
    "\n",
    "# If you want to create a new DataFrame for combined data\n",
    "df_combined = pd.DataFrame({'text': combined_contexts})\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cf2df43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/data/jzheng36/huggingface/datasets/ucberkeley-dlab___parquet/ucberkeley-dlab--measuring-hate-speech-c32713cabe528196/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62a785df3824fbba4b5b549870a790e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>platform</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>respect</th>\n",
       "      <th>insult</th>\n",
       "      <th>humiliate</th>\n",
       "      <th>status</th>\n",
       "      <th>dehumanize</th>\n",
       "      <th>violence</th>\n",
       "      <th>...</th>\n",
       "      <th>annotator_religion_hindu</th>\n",
       "      <th>annotator_religion_jewish</th>\n",
       "      <th>annotator_religion_mormon</th>\n",
       "      <th>annotator_religion_muslim</th>\n",
       "      <th>annotator_religion_nothing</th>\n",
       "      <th>annotator_religion_other</th>\n",
       "      <th>annotator_sexuality_bisexual</th>\n",
       "      <th>annotator_sexuality_gay</th>\n",
       "      <th>annotator_sexuality_straight</th>\n",
       "      <th>annotator_sexuality_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47777</td>\n",
       "      <td>10873</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39773</td>\n",
       "      <td>2790</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47101</td>\n",
       "      <td>3379</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43625</td>\n",
       "      <td>7365</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12538</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135551</th>\n",
       "      <td>37080</td>\n",
       "      <td>8590</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135552</th>\n",
       "      <td>22986</td>\n",
       "      <td>8303</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135553</th>\n",
       "      <td>21008</td>\n",
       "      <td>6207</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135554</th>\n",
       "      <td>22986</td>\n",
       "      <td>7886</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135555</th>\n",
       "      <td>14785</td>\n",
       "      <td>6897</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135556 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        comment_id  annotator_id  platform  sentiment  respect  insult  \\\n",
       "0            47777         10873         3        0.0      0.0     0.0   \n",
       "1            39773          2790         2        0.0      0.0     0.0   \n",
       "2            47101          3379         3        4.0      4.0     4.0   \n",
       "3            43625          7365         3        2.0      3.0     2.0   \n",
       "4            12538           488         0        4.0      4.0     4.0   \n",
       "...            ...           ...       ...        ...      ...     ...   \n",
       "135551       37080          8590         2        1.0      1.0     0.0   \n",
       "135552       22986          8303         2        2.0      0.0     0.0   \n",
       "135553       21008          6207         2        1.0      1.0     1.0   \n",
       "135554       22986          7886         2        2.0      0.0     0.0   \n",
       "135555       14785          6897         0        4.0      4.0     4.0   \n",
       "\n",
       "        humiliate  status  dehumanize  violence  ...  \\\n",
       "0             0.0     2.0         0.0       0.0  ...   \n",
       "1             0.0     2.0         0.0       0.0  ...   \n",
       "2             4.0     4.0         4.0       0.0  ...   \n",
       "3             1.0     2.0         0.0       0.0  ...   \n",
       "4             4.0     4.0         4.0       4.0  ...   \n",
       "...           ...     ...         ...       ...  ...   \n",
       "135551        0.0     2.0         0.0       0.0  ...   \n",
       "135552        0.0     2.0         0.0       0.0  ...   \n",
       "135553        1.0     1.0         0.0       0.0  ...   \n",
       "135554        0.0     2.0         0.0       0.0  ...   \n",
       "135555        2.0     2.0         2.0       3.0  ...   \n",
       "\n",
       "        annotator_religion_hindu  annotator_religion_jewish  \\\n",
       "0                          False                      False   \n",
       "1                          False                      False   \n",
       "2                          False                      False   \n",
       "3                          False                      False   \n",
       "4                          False                      False   \n",
       "...                          ...                        ...   \n",
       "135551                     False                      False   \n",
       "135552                     False                      False   \n",
       "135553                     False                      False   \n",
       "135554                     False                      False   \n",
       "135555                     False                      False   \n",
       "\n",
       "        annotator_religion_mormon  annotator_religion_muslim  \\\n",
       "0                           False                      False   \n",
       "1                           False                      False   \n",
       "2                           False                      False   \n",
       "3                           False                      False   \n",
       "4                           False                      False   \n",
       "...                           ...                        ...   \n",
       "135551                      False                      False   \n",
       "135552                      False                      False   \n",
       "135553                      False                      False   \n",
       "135554                      False                      False   \n",
       "135555                      False                      False   \n",
       "\n",
       "       annotator_religion_nothing  annotator_religion_other  \\\n",
       "0                           False                     False   \n",
       "1                           False                     False   \n",
       "2                            True                     False   \n",
       "3                           False                     False   \n",
       "4                           False                     False   \n",
       "...                           ...                       ...   \n",
       "135551                      False                     False   \n",
       "135552                      False                      True   \n",
       "135553                      False                     False   \n",
       "135554                       True                     False   \n",
       "135555                      False                     False   \n",
       "\n",
       "        annotator_sexuality_bisexual  annotator_sexuality_gay  \\\n",
       "0                              False                    False   \n",
       "1                              False                    False   \n",
       "2                              False                    False   \n",
       "3                              False                    False   \n",
       "4                              False                    False   \n",
       "...                              ...                      ...   \n",
       "135551                         False                    False   \n",
       "135552                          True                    False   \n",
       "135553                         False                    False   \n",
       "135554                         False                    False   \n",
       "135555                         False                    False   \n",
       "\n",
       "        annotator_sexuality_straight  annotator_sexuality_other  \n",
       "0                               True                      False  \n",
       "1                               True                      False  \n",
       "2                               True                      False  \n",
       "3                               True                      False  \n",
       "4                               True                      False  \n",
       "...                              ...                        ...  \n",
       "135551                          True                      False  \n",
       "135552                         False                      False  \n",
       "135553                          True                      False  \n",
       "135554                          True                      False  \n",
       "135555                          True                      False  \n",
       "\n",
       "[135556 rows x 131 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"ucberkeley-dlab/measuring-hate-speech\")\n",
    "train_data = dataset['train']\n",
    "df = pd.DataFrame(train_data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af5617e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate entries: 38694\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df[df['hate_speech_score'] > 0.5]\n",
    "contexts = filtered_df['text'].tolist()\n",
    "unique_contexts = set(contexts)\n",
    "duplicate_count = len(contexts) - len(unique_contexts)\n",
    "\n",
    "print(f\"Number of duplicate entries: {duplicate_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "276e5a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10354"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cce3f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.bias', 'question_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRReaderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-reader-single-nq-base were not used when initializing DPRReader: ['span_predictor.encoder.bert_model.pooler.dense.bias', 'span_predictor.encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRReader from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRReader from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Content mocking someone for their personality, opinions, character or emotional state\n",
      "Answer: racist\n",
      "Relevant Passage: Blah blah blah, even during a deadly pandemic there's still morons like this ngr playing the victim, Men are also disproportionately killed by coronavirus so not only is it racist it's also sexist ......\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (DPRContextEncoder, DPRContextEncoderTokenizer,\n",
    "                          DPRQuestionEncoder, DPRQuestionEncoderTokenizer,\n",
    "                          DPRReader, DPRReaderTokenizer)\n",
    "\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_model.eval()\n",
    "\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_model.eval()\n",
    "    \n",
    "def retrieve_and_extract(query, contexts):\n",
    "    \"\"\"\n",
    "    Retrieve top 5 passages and extract answers from them using DPR.\n",
    "    :param query: The query string.\n",
    "    :param contexts: List of context passages.\n",
    "    :return: Extracted answers and their corresponding passages.\n",
    "    \"\"\"\n",
    "\n",
    "    encoded_contexts = context_tokenizer(contexts, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    context_embeddings = context_model(**encoded_contexts).pooler_output\n",
    "    context_embeddings = context_embeddings / context_embeddings.norm(dim=1, keepdim=True)\n",
    "\n",
    "\n",
    "    encoded_query = question_tokenizer(query, return_tensors=\"pt\")\n",
    "    query_embeddings = question_model(**encoded_query).pooler_output\n",
    "    query_embeddings = query_embeddings / query_embeddings.norm(dim=1, keepdim=True)\n",
    "\n",
    "    # similarity scores\n",
    "    scores = torch.matmul(query_embeddings, context_embeddings.T).squeeze()\n",
    "    top_indices = torch.argsort(scores, descending=True)[:5].tolist()\n",
    "    top_passages = [contexts[idx] for idx in top_indices]\n",
    "\n",
    "    # Extract answers using DPRReader\n",
    "    reader_tokenizer = DPRReaderTokenizer.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "    reader = DPRReader.from_pretrained('facebook/dpr-reader-single-nq-base')\n",
    "    reader.eval()\n",
    "\n",
    "    inputs = reader_tokenizer(\n",
    "        questions=[query] * len(top_passages),\n",
    "        texts=top_passages,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "    outputs = reader(**inputs)\n",
    "    combined_logits = outputs.start_logits + outputs.end_logits\n",
    "    best_passage_idx = torch.argmax(combined_logits.sum(dim=1)).item()\n",
    "\n",
    "    start_idx = torch.argmax(outputs.start_logits[best_passage_idx]).item()\n",
    "    end_idx = torch.argmax(outputs.end_logits[best_passage_idx]).item()\n",
    "\n",
    "    answer = reader_tokenizer.decode(inputs.input_ids[best_passage_idx][start_idx:end_idx + 1], skip_special_tokens=True)\n",
    "\n",
    "    return answer, top_passages[best_passage_idx]\n",
    "\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep=\"\\t\")\n",
    "\n",
    "query = \"Content mocking someone for their personality, opinions, character or emotional state\"\n",
    "answer, relevant_passage = retrieve_and_extract(query, df['sentence'][:1000].tolist())\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {answer}\")\n",
    "print(f\"Relevant Passage: {relevant_passage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73508ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
