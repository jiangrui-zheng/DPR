{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4bb4c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-24T19:30:37.672275573Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "# Prepare Data\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, questions, contexts):\n",
    "        self.questions = questions\n",
    "        self.contexts = contexts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.questions[idx], self.contexts[idx]\n",
    "    \n",
    "    \n",
    "def dpr_criterion(scores):\n",
    "    return -torch.mean(torch.log(torch.diag(F.softmax(scores, dim=1))))\n",
    "    \n",
    "device = torch.device(\"cuda:0\") \n",
    "# device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep = \"\\t\").sample(frac=0.3).reset_index(drop=True)\n",
    "#contexts = df.loc[df['guideline'] == 'filth', 'sentence']\n",
    "contexts = df['sentence']\n",
    "questions = df['guideline']\n",
    "# Mock Data\n",
    "#questions = [\"What is climate change?\", \"How does vaccination work?\", \"What is AI?\", \"How does photosynthesis work?\"]\n",
    "#contexts = [\n",
    "    #\"Climate change is a long-term alteration of temperature and typical weather patterns.\",\n",
    "    #\"Vaccination is the administration of a vaccine to help the immune system develop protection from a disease.\",\n",
    "    #\"AI stands for Artificial Intelligence, a subfield of computer science that aims to create machines that can perform tasks requiring human intelligence.\",\n",
    "    #\"Photosynthesis is the process by which green plants and some other organisms use sunlight to synthesize foods with carbon dioxide and water.\"\n",
    "#]\n",
    "\n",
    "dataset = MyDataset(questions, contexts)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "batch_size = 2\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Initialize DPR model and tokenizer\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = AdamW([\n",
    "    {'params': context_model.parameters()},\n",
    "    {'params': question_model.parameters()}\n",
    "], lr=1e-5)\n",
    "\n",
    "epochs = 3\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_dataloader) * epochs)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop with validation\n",
    "for epoch in trange(epochs):\n",
    "    context_model.train()\n",
    "    question_model.train()\n",
    "    \n",
    "    # Training\n",
    "    with tqdm(total=len(train_dataloader), desc=\"training\", miniters=20) as pbar:\n",
    "        for batch in train_dataloader:\n",
    "            questions, passages = batch\n",
    "\n",
    "            question_inputs = question_tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            passage_inputs = context_tokenizer(passages, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            question_outputs = question_model(**question_inputs).pooler_output\n",
    "            passage_outputs = context_model(**passage_inputs).pooler_output\n",
    "            \n",
    "#             print(question_outputs.shape)\n",
    "#             print(passage_outputs.shape)\n",
    "\n",
    "            # targets = torch.diag(torch.ones(len(questions))).to(device)\n",
    "            similarity_scores = torch.matmul(question_outputs, torch.transpose(passage_outputs, 0, 1))\n",
    "            loss = dpr_criterion(similarity_scores)\n",
    "\n",
    "            \n",
    "#             print(targets)\n",
    "#             print(similarity_scores)\n",
    "            \n",
    "            # loss = criterion(similarity_scores, targets)\n",
    "#            print(loss)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            pbar.update(1)\n",
    "\n",
    "    # Validation\n",
    "    context_model.eval()\n",
    "    question_model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            questions, passages = batch\n",
    "            question_inputs = question_tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            passage_inputs = context_tokenizer(passages, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "            question_outputs = question_model(**question_inputs).pooler_output\n",
    "            passage_outputs = context_model(**passage_inputs).pooler_output \n",
    "            \n",
    "            # targets = torch.diag(torch.ones(len(questions))).to(device)\n",
    "            \n",
    "            \n",
    "            similarity_scores = torch.matmul(question_outputs, torch.transpose(passage_outputs, 0, 1))\n",
    "            loss = dpr_criterion(similarity_scores)\n",
    "#             loss = criterion(similarity_scores, targets)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch: {epoch+1}, Validation Loss: {val_loss / len(val_dataloader)}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(context_model.state_dict(), \"context_model.pth\")\n",
    "torch.save(question_model.state_dict(), \"question_model.pth\")\n",
    "\n",
    "# To load model\n",
    "# context_model.load_state_dict(torch.load(\"context_model.pth\"))\n",
    "# question_model.load_state_dict(torch.load(\"question_model.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4994855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizer'.\n",
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-single-nq-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at facebook/dpr-question_encoder-single-nq-base were not used when initializing DPRQuestionEncoder: ['question_encoder.bert_model.pooler.dense.weight', 'question_encoder.bert_model.pooler.dense.bias']\n",
      "- This IS expected if you are initializing DPRQuestionEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRQuestionEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import DPRContextEncoder, DPRContextEncoderTokenizer, DPRQuestionEncoder, DPRQuestionEncoderTokenizer, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import trange, tqdm\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(1)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "context_tokenizer = DPRContextEncoderTokenizer.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base')\n",
    "question_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained('facebook/dpr-question_encoder-single-nq-base')\n",
    "\n",
    "context_model = DPRContextEncoder.from_pretrained('facebook/dpr-ctx_encoder-single-nq-base').to(device)\n",
    "question_model = DPRQuestionEncoder.from_pretrained('facebook/dpr-question_encoder-single-nq-base').to(device)\n",
    "\n",
    "context_model.load_state_dict(torch.load(\"context_model.pth\"))\n",
    "question_model.load_state_dict(torch.load(\"question_model.pth\"))\n",
    "\n",
    "# def retrieve_passages(question_model, context_model, question_tokenizer, context_tokenizer, query, contexts):\n",
    "#     # Generate question embeddings\n",
    "#     question_inputs = question_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         question_embedding = question_model(**question_inputs).pooler_output\n",
    "\n",
    "#     # Generate context embeddings\n",
    "#     context_inputs = context_tokenizer(contexts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         context_embeddings = context_model(**context_inputs).pooler_output\n",
    "\n",
    "#     # Calculate similarity between question and context embeddings\n",
    "#     similarity_scores = torch.matmul(question_embedding, torch.transpose(context_embeddings, 0, 1)).squeeze()\n",
    "\n",
    "#     # Sort the similarity scores and get the indices of the top 5 similar contexts\n",
    "#     sorted_indices = torch.argsort(similarity_scores, descending=True)[:5]\n",
    "\n",
    "#     # Retrieve the top 5 similar context passages\n",
    "#     top_contexts = [contexts[idx] for idx in sorted_indices.tolist()]\n",
    "\n",
    "#     return top_contexts\n",
    "\n",
    "# def compute_relevance(query, context):\n",
    "#     # Generate question embeddings\n",
    "#     question_inputs = question_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#     context_inputs = context_tokenizer(contexts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "#     with torch.no_grad():\n",
    "#         question_embedding = question_model(**question_inputs).pooler_output\n",
    "#         context_embeddings = context_model(**context_inputs).pooler_output\n",
    "\n",
    "#         # Calculate similarity between question and context embeddings\n",
    "#         similarity_score = torch.matmul(question_embedding, torch.transpose(context_embeddings, 0, 1)).squeeze()\n",
    "\n",
    "#     return similarity_score.cpu().numpy()\n",
    "\n",
    "# df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep = \"\\t\").reset_index(drop=True)\n",
    "# #contexts = df.loc[df['guideline'] == 'filth', 'sentence']\n",
    "\n",
    "# # Your list of context passages\n",
    "# query = \"filth\"\n",
    "# contexts = df['sentence'][:].tolist()\n",
    "\n",
    "# for context in tqdm(contexts):\n",
    "#     score = compute_relevance(query, context)\n",
    "#     scores.append(score)\n",
    "\n",
    "\n",
    "\n",
    "# # Perform retrieval\n",
    "# top_contexts = retrieve_passages(\n",
    "#     question_model,\n",
    "#     context_model,\n",
    "#     question_tokenizer,\n",
    "#     context_tokenizer,\n",
    "#     query,\n",
    "#     contexts\n",
    "# )\n",
    "\n",
    "# # Display the results\n",
    "# for i, context in enumerate(top_contexts):\n",
    "#     print(f\"Rank {i+1}: {context}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c03bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4651/4651 [01:07<00:00, 69.04it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_top_documents(query, df, topk=10):\n",
    "    scores = list()\n",
    "    for context in tqdm(contexts):\n",
    "        score = compute_relevance(query, context)\n",
    "        scores.append(score)\n",
    "    \n",
    "    df[\"score\"] = scores\n",
    "    return df.sort_values(by=\"score\", ascending=False).sentence.tolist()[:topk]\n",
    "    \n",
    "\n",
    "def compute_relevance(query, context):    \n",
    "    # Generate question embeddings\n",
    "    question_inputs = question_tokenizer(query, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    context_inputs = context_tokenizer(context, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        question_embedding = question_model(**question_inputs).pooler_output\n",
    "        context_embeddings = context_model(**context_inputs).pooler_output\n",
    "\n",
    "        # Calculate similarity between question and context embeddings\n",
    "        similarity_score = torch.matmul(question_embedding, torch.transpose(context_embeddings, 0, 1)).squeeze()\n",
    "\n",
    "    return similarity_score.cpu().numpy()\n",
    "    \n",
    "\n",
    "query = \"Mocking others due to their personality.\"\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep = \"\\t\").reset_index(drop=True)\n",
    "\n",
    "retrieved_documents = get_top_documents(query, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbc8cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The only thing men hate more than a woman who's being snarky or sarcastic or \"\n",
      " \"bitchy, is a woman who's genuinely trying to use snark or sarcasm to be \"\n",
      " 'funny or sweet or attractive or \"\"cute\"\". Snark, sarcasm and bitchiness have '\n",
      " \"nothing to do with these things. They're annoying. They're tiresome. They're \"\n",
      " \"agitating. They're off-putting. They're the opposite of attractive. It \"\n",
      " \"doesn't make her look attractive. It just makes her look like a crazy bitch.\",\n",
      " 'Blackface is a great way to mock black people.',\n",
      " 'Blackface is the perfect way to make fun of African Americans.',\n",
      " 'People should wear blackface to make fun of black people.',\n",
      " 'I remember how uncomfortable he felt when I used to hear the others call my '\n",
      " \"childhood's friend darky, but in retrospect I think he deserved it\",\n",
      " 'my heart genuinely rejoices whenver I see a chink being made a fool of in '\n",
      " \"public, like falling over or hurting themselves. it's a public display of \"\n",
      " 'what they deserve',\n",
      " 'Blackface performances are a great way to poke fun at African Americans.',\n",
      " 'Putting on blackface is the best way to insult African Americans.',\n",
      " 'Most sluts are for sleeping with, and never for marrying. What are they? not '\n",
      " \"a virgin when you start dating her, dresses in a way that you don't have to \"\n",
      " 'use much of your imagination to know what her body looks like (leggings as '\n",
      " 'pants, bikinis, spandex as clothes, dresses and shorts so short that you can '\n",
      " 'see all of their legs or even some of their ass) engaging in behavior that '\n",
      " \"repeatedly gets the sexual attention of men, especially when they're in a \"\n",
      " \"relationship. it doesn't matter whether she says it's not for getting the \"\n",
      " 'male attention. pay attention to their actions, not their words. if you feel '\n",
      " 'a certain way, it was intended to be that way. so if a girl dresses in a way '\n",
      " \"that turns heads because she's showing off enough of her body, she's doing \"\n",
      " 'it on purpose These girls are not worth marrying. Maybe dating for a short '\n",
      " \"period of time, just don't get invested emotionally.\",\n",
      " 'Exactly. The \"\"anti degenerates\"\" such as this guy and PJW etc, simply '\n",
      " \"don't get human nature and the fact that women, those that haven't been \"\n",
      " 'infected by horseshit, women are natural show offs who want to show us their '\n",
      " 'stuff. On one hand they piss and moan about women being covered by hijabs '\n",
      " 'and robes and then get all high and mighty when they flash their stuff as '\n",
      " 'cam whores. Fuck these prude twats.']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40fbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"scores\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "886fc2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>dataset</th>\n",
       "      <th>index</th>\n",
       "      <th>guideline</th>\n",
       "      <th>votes</th>\n",
       "      <th>labelers</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4369</th>\n",
       "      <td>11708</td>\n",
       "      <td>I endorse the attacking of gay people</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>1191</td>\n",
       "      <td>attack concept associated protected characteri...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>2;4</td>\n",
       "      <td>46.91195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4469</th>\n",
       "      <td>11823</td>\n",
       "      <td>I endorse the attacking of homosexuals</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>39198</td>\n",
       "      <td>attack concept associated protected characteri...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>2;4</td>\n",
       "      <td>46.975536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>11830</td>\n",
       "      <td>I endorse the attacking of jews</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>39190</td>\n",
       "      <td>attack concept associated protected characteri...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>2;4</td>\n",
       "      <td>47.009098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4492</th>\n",
       "      <td>11846</td>\n",
       "      <td>I endorse the attacking of muslims</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>39173</td>\n",
       "      <td>attack concept associated protected characteri...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>2;4</td>\n",
       "      <td>47.10845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4475</th>\n",
       "      <td>11829</td>\n",
       "      <td>I endorse the attacking of jewish people</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>39192</td>\n",
       "      <td>attack concept associated protected characteri...</td>\n",
       "      <td>1;1</td>\n",
       "      <td>2;4</td>\n",
       "      <td>47.176685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73</td>\n",
       "      <td>Disabled people are worthless dirt.</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>291</td>\n",
       "      <td>filth</td>\n",
       "      <td>1;1;1</td>\n",
       "      <td>10;11;2</td>\n",
       "      <td>66.559425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>106</td>\n",
       "      <td>You are absolute filth</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>2996</td>\n",
       "      <td>filth</td>\n",
       "      <td>1;1;1</td>\n",
       "      <td>10;11;2</td>\n",
       "      <td>66.83118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>82</td>\n",
       "      <td>Immigrants like you are absolute filth.</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>300</td>\n",
       "      <td>filth</td>\n",
       "      <td>1;1;1</td>\n",
       "      <td>10;11;2</td>\n",
       "      <td>67.11209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>103</td>\n",
       "      <td>Immigrants like you are absolute filth.</td>\n",
       "      <td>hatecheck</td>\n",
       "      <td>300</td>\n",
       "      <td>filth</td>\n",
       "      <td>1;1;1</td>\n",
       "      <td>10;11;2</td>\n",
       "      <td>67.11209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>wommennnnnn are dirt</td>\n",
       "      <td>dynahate</td>\n",
       "      <td>4838</td>\n",
       "      <td>filth</td>\n",
       "      <td>1;1;1</td>\n",
       "      <td>10;11;2</td>\n",
       "      <td>67.18407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4651 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      example_id                                  sentence    dataset  index  \\\n",
       "4369       11708     I endorse the attacking of gay people   dynahate   1191   \n",
       "4469       11823    I endorse the attacking of homosexuals   dynahate  39198   \n",
       "4476       11830           I endorse the attacking of jews   dynahate  39190   \n",
       "4492       11846        I endorse the attacking of muslims   dynahate  39173   \n",
       "4475       11829  I endorse the attacking of jewish people   dynahate  39192   \n",
       "...          ...                                       ...        ...    ...   \n",
       "12            73       Disabled people are worthless dirt.  hatecheck    291   \n",
       "36           106                    You are absolute filth  hatecheck   2996   \n",
       "21            82   Immigrants like you are absolute filth.  hatecheck    300   \n",
       "35           103   Immigrants like you are absolute filth.  hatecheck    300   \n",
       "0             31                      wommennnnnn are dirt   dynahate   4838   \n",
       "\n",
       "                                              guideline  votes labelers  \\\n",
       "4369  attack concept associated protected characteri...    1;1      2;4   \n",
       "4469  attack concept associated protected characteri...    1;1      2;4   \n",
       "4476  attack concept associated protected characteri...    1;1      2;4   \n",
       "4492  attack concept associated protected characteri...    1;1      2;4   \n",
       "4475  attack concept associated protected characteri...    1;1      2;4   \n",
       "...                                                 ...    ...      ...   \n",
       "12                                                filth  1;1;1  10;11;2   \n",
       "36                                                filth  1;1;1  10;11;2   \n",
       "21                                                filth  1;1;1  10;11;2   \n",
       "35                                                filth  1;1;1  10;11;2   \n",
       "0                                                 filth  1;1;1  10;11;2   \n",
       "\n",
       "         scores  \n",
       "4369   46.91195  \n",
       "4469  46.975536  \n",
       "4476  47.009098  \n",
       "4492   47.10845  \n",
       "4475  47.176685  \n",
       "...         ...  \n",
       "12    66.559425  \n",
       "36     66.83118  \n",
       "21     67.11209  \n",
       "35     67.11209  \n",
       "0      67.18407  \n",
       "\n",
       "[4651 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=\"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../postprocess/all_examples_0601_hate.csv', sep = \"\\t\")\n",
    "contexts = df.loc[df['guideline'] == 'filth', 'sentence']\n",
    "contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9875e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
